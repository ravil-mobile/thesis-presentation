\section{Methodology and Matrix Sets}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[t]{Static Solver Configuration}
    \footnotesize
    \justifying
    \begin{itemize}
        \setlength\itemsep{0.25cm}
        \item ATHLET is a CFD tool dedicated to \textbf{transient problems}
        \item Additionally, \textbf{topology} of hydrolic circuits can \textbf{be changed} during simulation-time
        \item Hence, the Jacobian matrix \textbf{structure} can \textbf{vary} significantly during numerical itegration
    \end{itemize}
    
    \small
    \begin{block}{Therefore:}
        \begin{enumerate}
            \item Configuration of a linear solver in run-time is compute-intensive and time consuming
            
            \item Reults of dynamic solver configuration can be ambiguous and difficult to interpret
            
            \item A feasible and doable approach is \textbf{static solver configuration}
        \end{enumerate}
    \end{block}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[t]{GRS Matrix Set}
    \spc
    \justifying
    
    GRS \textbf{matrix set} was generated by \textbf{running} the most \textbf{common GRS simulations} in ATHLET and \textbf{stopping} them \textbf{somewhere in the middle}. The corresponding shifted Jacobian matrices ware saved in the PETSc binary format.
    
    \begin{table}[ht]
        \small
        \centering
        \begin{tabular}{|c|c|c|c|c|}
        \hline
        Name     & n       & nnz      & nnz / n & \begin{tabular}[c]{@{}c@{}}Approximate\\ Condition\\ Number\end{tabular} \\ \hline
        pwr-3d   & 6009    & 32537    & 5.4147  & 1.019e+07
         \\ \hline
        cube-5   & 9325    & 117897   & 12.6431 & 1.592e+09                                                                \\ \hline
        cube-64  & 100657  & 1388993  & 13.7993 & 7.406e+08                                                                \\ \hline
        cube-645 & 1000045 & 13906057 & 13.9054 & 6.474e+08
         \\ \hline
        k3-2     & 130101  & 787997   & 6.0568  & 1.965e+15                                                                \\ \hline
        k3-18    & 1155955 & 7204723  & 6.2327  & 1.947e+12                                                                \\ \hline
        \end{tabular}
        \caption{GRS matrix set}
        \label{table:grs-matrix-set}
\end{table}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[t]{SuiteSparse Matrix Set}
    \spc
    \justifying
    \textbf{SiteSparse} matrix set was generated by \textbf{downloading} a dozen of matrices from SuiteSparse Matrix Collection \cite{sparse-matrix-collection:1}, \cite{sparse-matrix-collection:2}, with the \textbf{aim} of \textbf{comparison} and \textbf{verification} of solver configurations
    
    \begin{table}[ht]
\centering
\footnotesize
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Name        & n       & nnz      & nnz / n & \begin{tabular}[c]{@{}c@{}}Approximate\\ Condition\\ Number\end{tabular} \\ \hline
cant        & 62451   & 4007383  & 64.1684 & 5.082e+05\\ \hline
consph      & 83334   & 6010480  & 72.1251 & 2.438e+05\\ \hline
CurlCurl\_3 & 1219574 & 13544618 & 11.1060 & 2.105e+05\\ \hline
Geo\_1438   & 1437960 & 63156690 & 43.9210 & 4.677e+05\\ \hline
memchip     & 2707524 & 13343948 & 4.9285  & 1.305e+07\\ \hline
PFlow\_742  & 742793  & 37138461 & 49.9984 & 5.553e+06\\ \hline
pkustk10    & 80676   & 4308984  & 53.4110 & 5.589e+02\\ \hline
torso3      & 259156  & 4429042  & 7.0903  & 2.456e+03\\ \hline
x104        & 108384  & 8713602  & 80.3956 & 3.124e+05\\ \hline
\end{tabular}
\caption{SuiteSparse matrix set}
\label{table:suite-sparse-matrix-set}
\end{table}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Hardware}
    \begin{table}[ht]
\centering
\footnotesize
\begin{tabular}{|l|c|c|}
\hline
                    & HW1 (GRS) & HW2 (LRZ Linux) \\ \hline
CPU(s)              & 20 &  28 \\ \hline
On-line CPU(s) list & 0-19 &  0-27 \\ \hline
Thread(s) per core  & 1 &  1 \\  \hline
Core(s) per socket  & 10 & 14 \\ \hline
Socket(s)           & 2 &  2 \\ \hline
NUMA node(s)        & 2 &  4 \\ \hline
Model name          & E5-2680 v2 & 
E5-2697 v3 \\ \hline
Stepping            & 4 &  2 \\ \hline
CPU MHz             & 1200.0 &  2036.707 \\ \hline
L1 d/i cache        & 32K/32K &  32K/32K \\ \hline
L2 cache            & 256K &  256K \\ \hline
L3 cache            & 25600K &  17920K \\ \hline
NUMA node0 CPU(s)   & 0-9 &  0-6 \\ \hline
NUMA node1 CPU(s)   & 10-19 &  7-13 \\ \hline
NUMA node2 CPU(s)   & - &  14-20 \\ \hline
NUMA node3 CPU(s)   & - &  21-27 \\ \hline
\end{tabular}
\caption{Hardware specification}
\label{table:hardware-spec}
\end{table}
    
\end{frame}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Experimental setup}

    \justifying
    
    \begin{block} {Libraries and Compiler}
        \begin{enumerate}
            \item PETSc version 3.10
        \item OpenMPI version 3.1.1
            \item Intel Compiler 18
        \end{enumerate}
    \end{block}

\end{frame}
